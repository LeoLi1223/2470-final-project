{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ARiGr47j7T-I"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-04 15:57:03.111709: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "from model import ImageCaptionModel\n",
        "from decoder import TransformerDecoder, RNNDecoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-04 02:01:34.066622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Getting training embeddings\n",
            "2024-05-04 02:02:04.833406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[(240/240)] Processing '../memes900k/images/i-will-find-you-meme.jpg' into 2048-\n",
            "\n",
            "Getting testing embeddings\n",
            "[(60/60)] Processing '../memes900k/images/trologirl.jpg' into 2048-D Inception V\n",
            "\n",
            "Data has been dumped into ../memes900k/data.p!\n"
          ]
        }
      ],
      "source": [
        "!python preprocessing.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check metadata of the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_captions:   (36000, 21)\n",
            "test_captions:    (9000, 21)\n",
            "\n",
            "train_img_feats:  (36000, 2048)\n",
            "test_img_feats:   (9000, 2048)\n",
            "\n",
            "train_images:     (36000, 299, 299, 3)\n",
            "test_images:      (9000, 299, 299, 3)\n"
          ]
        }
      ],
      "source": [
        "## Before this, download the dataset and run preprocessing.py as instructed. \n",
        "## This may take like 10 mins, but should only happen once so ok.\n",
        "## https://www.kaggle.com/datasets/adityajn105/flickr8k?resource=download\n",
        "\n",
        "with open('../memes900k/data.p', 'rb') as data_file:\n",
        "    data_dict = pickle.load(data_file)\n",
        "\n",
        "# As mentioned in the handout, this assignment has 5 captions per image. This block of code \n",
        "# expands the image_feature lists to have 5 copies of each image to correspond to each of their captions \n",
        "feat_prep = lambda x: np.repeat(np.array(x).reshape(-1, 2048), 150, axis=0)\n",
        "img_prep  = lambda x: np.repeat(x, 150, axis=0)\n",
        "\n",
        "## Captions; preprocessed sentences with 20 window size\n",
        "train_captions  = np.array(data_dict['train_captions']);            print('train_captions:  ', train_captions.shape)\n",
        "test_captions   = np.array(data_dict['test_captions']);             print('test_captions:   ', test_captions.shape)\n",
        "\n",
        "## 2048-D resnet embeddings of images.\n",
        "train_img_feats = feat_prep(data_dict['train_image_features']);     print('\\ntrain_img_feats: ', train_img_feats.shape)\n",
        "test_img_feats  = feat_prep(data_dict['test_image_features']);      print('test_img_feats:  ', test_img_feats.shape)\n",
        "\n",
        "## Small subset of actual images for visualization purposes. \n",
        "## These are just for the first 100 images of each (clones 5 times)\n",
        "train_images    = img_prep(data_dict['train_images']);              print('\\ntrain_images:    ', train_images.shape)\n",
        "test_images     = img_prep(data_dict['test_images']);               print('test_images:     ', test_images.shape)\n",
        "\n",
        "## Conversion dictionaries to go between word and label index\n",
        "word2idx        = data_dict['word2idx']\n",
        "idx2word        = data_dict['idx2word']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iIKs4lo0iIo"
      },
      "source": [
        "### Running your RNN model\n",
        "\n",
        "Depending on your use cases, you may choose to structure your model in a variety of ways. In contrast to previous assignments, this one is intended to mimic a lot of modern research-oriented repositories you might find in the wild. Specifically: **Instead of providing easy-to-use APIs for experimenters, they rigidify their implementation to make tests replicable.** Specifically, they may provide a command-line interface and define testing/training procedures which log results. \n",
        "\n",
        "(I mean, ideally you can make a flexible API and allow for both ease of extension and examples to demonstrate how your results were gathered, but sometimes researchers only have so much time...)\n",
        "\n",
        "Once you have filled in the `model.py` components and the `RNNDecoder` of the `decoder.py` file, run this block to train your RNN model. As you can see, the hyperparamets default to the ones you use in `assignment.py`'s argparse specification, but feel free to change any of them to try to improve your model. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvWXYsyQ0iIp"
      },
      "source": [
        "### Running your Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xDXL5-huovlE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-04 15:57:54.458102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Found 400000 word vectors.\n",
            "2024-05-04 15:58:29.319625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Converted 18005 words (2058 misses)\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/leo/Desktop/Brown/Spring24/CSCI2470/2470-final-project/code/main.py\", line 198, in <module>\n",
            "    main(parse_args())\n",
            "  File \"/Users/leo/Desktop/Brown/Spring24/CSCI2470/2470-final-project/code/main.py\", line 98, in main\n",
            "    train_model(\n",
            "  File \"/Users/leo/Desktop/Brown/Spring24/CSCI2470/2470-final-project/code/main.py\", line 175, in train_model\n",
            "    stats += [model.train(captions, img_feats, pad_idx, batch_size=args.batch_size)]\n",
            "  File \"/Users/leo/Desktop/Brown/Spring24/CSCI2470/2470-final-project/code/model.py\", line 39, in train\n",
            "    train_image_features = tf.gather(train_image_features, shuffled_indices)\n",
            "  File \"/Users/leo/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/Users/leo/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 7215, in raise_from_not_ok_status\n",
            "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[1128] = 14884 is not in [0, 12000) [Op:GatherV2]\n"
          ]
        }
      ],
      "source": [
        "## TODO: Increase epochs to a larger size when ready (maybe 2 or 3 would be enough?)\n",
        "!python main.py --type transformer --task train --data ../memes900k/data.p --epochs 10 --lr 0.0005 --chkpt_path ../transform_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71_bkKyU0iIq"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "After training our Transformer model, you can visualize the self-attention layer to examine the behavior of your attention heads and see if any patterns emerge. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpz85avktKxt"
      },
      "source": [
        "To test out the components of the model interactively, you'll need to deconstruct selections of the model/runner code and get an instance of the model in an interactive context (aka inside the notebook). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-04 02:27:42.786788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model loaded from '../transform_model'\n"
          ]
        }
      ],
      "source": [
        "## Feel free to insert auto-reloads as necessary\n",
        "from main import parse_args, load_model\n",
        "from decoder import TransformerDecoder, RNNDecoder\n",
        "\n",
        "## Pull your model into the notebook. This is heavily based off of assignment.py, \n",
        "## and feel free to reuse as much as you want. Your final project will probably \n",
        "## involve a lot of this investigative reverse-engineering based on what repos \n",
        "## you have to stumble upon.\n",
        "## You're not in a notebook scenario, so use get_default_arguments and feel free to update it...\n",
        "\n",
        "args = parse_args('--type rnn --task both --data ../memes900k/data.p'.split())\n",
        "\n",
        "args.chkpt_path = '../transform_model'\n",
        "tra_imcap = load_model(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"image_caption_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer_decoder (Transf  multiple                 8354528   \n",
            " ormerDecoder)                                                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,354,528\n",
            "Trainable params: 8,354,528\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tra_imcap.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTTYAclU7ALb"
      },
      "source": [
        "### Caption Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zar8W0Zn7Lnr"
      },
      "source": [
        " \n",
        "\n",
        "\n",
        "\n",
        "There is still one piece of this equation missing. The tokens are sampled from the probabilities your models generate, but your models were required to output logits, not probabilities. This is becasue this assignment, like many NLP models, uses temperature as a parameter in text generation. If the models sampled from  probabilies calculated by simply applying softmax to the logits, then the probability of the most likely word will usually be very high and the models will usually genrate the same, most probable caption every time. We use the temperature as a parameter to even out the probabilites so the model produces more 'creative' captions. This is done by dividing the logits by the temperature parameter before applying softmax. Higher temprature values will give a more creative captiong, while temprature values closer to 0 will be more greedy. Check out [this](https://lukesalamone.github.io/posts/what-is-temperature/) article for a demonstration and further explaination of temprature in NLP models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z_DpuFiYMOIa"
      },
      "outputs": [],
      "source": [
        "def gen_caption_temperature(model, image_embedding, wordToIds, padID, temp, window_length):\n",
        "    \"\"\"\n",
        "    Function used to generate a caption using an ImageCaptionModel given\n",
        "    an image embedding.\n",
        "    \"\"\"\n",
        "    idsToWords = {id: word for word, id in wordToIds.items()}\n",
        "    unk_token = wordToIds['<unk>']\n",
        "    caption_so_far = [wordToIds['<start>']]\n",
        "    while len(caption_so_far) < window_length and caption_so_far[-1] != wordToIds['<end>']:\n",
        "        caption_input = np.array([caption_so_far + ((window_length - len(caption_so_far)) * [padID])])\n",
        "        logits = model(np.expand_dims(image_embedding, 0), caption_input)\n",
        "        logits = logits[0][len(caption_so_far) - 1]\n",
        "        probs = tf.nn.softmax(logits / temp).numpy()\n",
        "        next_token = unk_token\n",
        "        attempts = 0\n",
        "        while next_token == unk_token and attempts < 5:\n",
        "            next_token = np.random.choice(len(probs), p=probs)\n",
        "            attempts += 1\n",
        "        caption_so_far.append(next_token)\n",
        "    out = []\n",
        "    for x in caption_so_far:\n",
        "      word = idsToWords[x]\n",
        "      if word == \"sep\":\n",
        "        word = \"<newline>\"\n",
        "      elif word == \"emp\":\n",
        "        continue\n",
        "      out.append(word)\n",
        "    return ' '.join(out[1:-1])\n",
        "    # return ' '.join([idsToWords[x] for x in caption_so_far][1:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## generate captions on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temperature = 0.05\n",
        "indices = np.random.choice(np.array(list(range(0, 500, 5))), 10, replace=False)\n",
        "for i in indices:\n",
        "    curr_image_feat = train_img_feats[i]\n",
        "    curr_image      = train_images[i]\n",
        "    for j in range(5):  ## Display all of the captions trained on\n",
        "        words = [idx2word[x] for x in train_captions[i+j][:-1] if idx2word[x] not in ('<pad>', '<start>', '<end>')]\n",
        "        print(f'C{j+1}:', ' '.join(words))\n",
        "    print('RNN:', gen_caption_temperature(rnn_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size))\n",
        "    print('TRA:', gen_caption_temperature(tra_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size))\n",
        "    plt.imshow(curr_image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## generate captions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: hey girl <newline> 0.1534\n",
            "filtered hey girl <newline> 0.1534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: if you could just <newline> 0.0805\n",
            "filtered <newline> 0.1625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: not sure if you re going to make sure if you <newline> or just really tired 0.1213\n",
            "filtered not sure if you re going to make sure if you <newline> or just really tired 0.1213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: the fuck <newline> 0.1932\n",
            "filtered the fuck <newline> 0.1932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: you want to be <newline> no one 0.082\n",
            "filtered you can be <newline> no one day 0.0824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: <newline> so can be great 0.0772\n",
            "filtered <newline> 0.1625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: you know what you know what you know what you know what you mean to be <newline> 0.0498\n",
            "filtered you know what you mean <newline> 0.0765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: you know what do you <newline> it 0.0992\n",
            "filtered you know what do you <newline> it 0.0992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: and then said <newline> and will be 0.0935\n",
            "filtered and then said <newline> and will be 0.0935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-offensive.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unfiltered: what if told you <newline> you don think it 0.1288\n",
            "filtered what if told you <newline> you don think it 0.1288\n"
          ]
        }
      ],
      "source": [
        "temperature = 0.05\n",
        "indices = np.random.choice(np.array(list(range(0, 3000, 50))), 10, replace=False)\n",
        "tra_captions = []\n",
        "for i in indices:\n",
        "    curr_image_feat = test_img_feats[i]\n",
        "    tra_caption = gen_caption_temperature(tra_imcap, curr_image_feat, word2idx, word2idx['<pad>'], temperature, args.window_size)\n",
        "    tra_captions.append(tra_caption)\n",
        "    #plt.imshow(curr_image)\n",
        "    #plt.show()\n",
        "    unfiltered_text, s1 = tra_imcap.get_unfiltered_captions(curr_image_feat, word2idx, word2idx['<pad>'], args.window_size)\n",
        "    filtered_text, s2 = tra_imcap.get_filtered_captions(curr_image_feat, word2idx, word2idx['<pad>'], args.window_size)\n",
        "    print(\"unfiltered:\", unfiltered_text, s1)\n",
        "    print(\"filtered\", filtered_text, s2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from filter_utils import print_captions_and_label\n",
        "print_captions_and_label(tra_captions, \"offensive\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "im_cap_notebook.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('dl3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "895b6b526044b58cdb0796603b6137eb4df401700b6bb2bfb9582034a97581c4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
